{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from __future__ import division, print_function # Imports from __future__ since we're running Python 2\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "\n",
    "import itertools\n",
    "from tabulate import tabulate\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "%run '/home/mark/Desktop/Plastic-Parallel-Programming/data_analysis/year 2/utilities.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Program parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine = \"XXXII\"\n",
    "\n",
    "instances = [\"cpu_small\", \"cpu_large\", \"vm_small\", \"vm_large\"]\n",
    "configurations = list(itertools.combinations_with_replacement(instances, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_tests = 729\n",
    "num_workers_max = 12\n",
    "num_cores_max   = 12\n",
    "    \n",
    "root_folder_path = \"results/\" + machine + \"/\"\n",
    "\n",
    "file_names = []\n",
    "\n",
    "for i in range(1, number_of_tests + 1): \n",
    "    file_names.append(\"test\" + str(i) + \"/output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path, dirs, files = os.walk(root_folder_path).next()\n",
    "num_exps = int(len(dirs) / 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0*np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * sp.stats.t._ppf((1+confidence)/2., n-1)\n",
    "    return int(round(m-h)), int(round(m)), int(round(m+h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51b9e6c86d894e8db4a5b9595693e25d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu_small cpu_small cpu_small completed\n",
      "cpu_small cpu_small cpu_large completed\n",
      "cpu_small cpu_small vm_small completed\n",
      "cpu_small cpu_small vm_large completed\n",
      "cpu_small cpu_large cpu_large completed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_data = []\n",
    "\n",
    "for exp_number in tqdm_notebook(range(1, num_exps + 1)):\n",
    "    \n",
    "    number_of_tests = 729\n",
    "    num_workers_max = 12\n",
    "    num_cores_max   = 12\n",
    "\n",
    "    data1 = []\n",
    "    data2 = []\n",
    "    data3 = []\n",
    "\n",
    "    fetch_data(root_folder_path + \"/exp_\" + str(exp_number) + \"_1/\", file_names, data1, [\"Runtime\"])\n",
    "    fetch_data(root_folder_path + \"/exp_\" + str(exp_number) + \"_2/\", file_names, data2, [\"Runtime\"])\n",
    "    fetch_data(root_folder_path + \"/exp_\" + str(exp_number) + \"_3/\", file_names, data3, [\"Runtime\"])\n",
    "\n",
    "    dataset = []\n",
    "    raw_dataset = []\n",
    "\n",
    "    num_workers_min = 4\n",
    "    num_workers_step = 4\n",
    "    num_workers_values = range(num_workers_min, num_workers_max + num_workers_step, num_workers_step)\n",
    "    nwv_len = len(num_workers_values)\n",
    "    num_workers = num_workers_values[0]\n",
    "\n",
    "    num_cores_min = 4\n",
    "    num_cores_step = 4\n",
    "    num_cores_values = range(num_cores_min, num_cores_max + num_cores_step, num_cores_step)\n",
    "    ncv_len = len(num_cores_values)\n",
    "    num_cores = num_cores_values[0]\n",
    "\n",
    "    for i in range(len(data1)):\n",
    "        num_workers3 = num_workers_values[i % nwv_len]\n",
    "        num_cores3   = num_cores_values[(i // nwv_len) % ncv_len]\n",
    "        num_workers2 = num_workers_values[((i // nwv_len) // ncv_len) % nwv_len]\n",
    "        num_cores2   = num_cores_values[(((i // nwv_len) // ncv_len) // nwv_len) % ncv_len]\n",
    "        num_workers1 = num_workers_values[((((i // nwv_len) // ncv_len) // nwv_len) // ncv_len) % nwv_len]\n",
    "        num_cores1   = num_cores_values[(((((i // nwv_len) // ncv_len) // nwv_len) // ncv_len) // nwv_len) % ncv_len]\n",
    "\n",
    "        dataset.append([num_cores1, num_workers1, num_cores2, num_workers2, num_cores3, num_workers3, np.mean([x + y + z for x, y, z in zip(data1[i].values, data2[i].values, data3[i].values)])])\n",
    "\n",
    "        for j in range(1, len(data1[i])):\n",
    "            raw_dataset.append([num_cores1, num_workers1, num_cores2, num_workers2, num_cores3, num_workers3, data1[i].values[j][0] + data2[i].values[j][0] + data3[i].values[j][0]])\n",
    "\n",
    "    dataset = pd.DataFrame(dataset)\n",
    "    dataset.columns = [\"Num Cores 1\", \"Num Workers 1\", \"Num Cores 2\", \"Num Workers 2\", \"Num Cores 3\", \"Num Workers 3\", \"Total Runtime\"]\n",
    "\n",
    "    raw_dataset = pd.DataFrame(raw_dataset)\n",
    "    raw_dataset.columns = [\"Num Cores 1\", \"Num Workers 1\", \"Num Cores 2\", \"Num Workers 2\", \"Num Cores 3\", \"Num Workers 3\", \"Total Runtime\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    min_record = dataset[dataset[\"Total Runtime\"] == min(dataset[\"Total Runtime\"])]\n",
    "\n",
    "    nc1 = dataset[dataset[\"Total Runtime\"] == min(dataset[\"Total Runtime\"])][\"Num Cores 1\"].item()\n",
    "    nc2 = dataset[dataset[\"Total Runtime\"] == min(dataset[\"Total Runtime\"])][\"Num Cores 2\"].item()\n",
    "    nc3 = dataset[dataset[\"Total Runtime\"] == min(dataset[\"Total Runtime\"])][\"Num Cores 3\"].item()\n",
    "\n",
    "    nw1 = dataset[dataset[\"Total Runtime\"] == min(dataset[\"Total Runtime\"])][\"Num Workers 1\"].item()\n",
    "    nw2 = dataset[dataset[\"Total Runtime\"] == min(dataset[\"Total Runtime\"])][\"Num Workers 2\"].item()\n",
    "    nw3 = dataset[dataset[\"Total Runtime\"] == min(dataset[\"Total Runtime\"])][\"Num Workers 3\"].item()\n",
    "\n",
    "    min_record_value = min_record[\"Total Runtime\"].item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if machine == \"spa\":\n",
    "        number_of_tests = 144\n",
    "        num_workers_max = 24\n",
    "        num_cores_max   = 24\n",
    "\n",
    "    elif machine == \"XXXII\":\n",
    "        number_of_tests = 576\n",
    "        num_workers_max = 48\n",
    "        num_cores_max   = 48\n",
    "\n",
    "\n",
    "\n",
    "    file_names = []\n",
    "\n",
    "    for i in range(1, number_of_tests + 1): \n",
    "        file_names.append(\"test\" + str(i) + \"/output\")\n",
    "\n",
    "    data1 = []\n",
    "    data2 = []\n",
    "    data3 = []\n",
    "\n",
    "    fetch_data(\"../optimal_threads/results/\" + machine + \"/optimal_threads_\" + configurations[exp_number - 1][0] + \"/\", file_names, data1, [\"Runtime\"])\n",
    "    fetch_data(\"../optimal_threads/results/\" + machine + \"/optimal_threads_\" + configurations[exp_number - 1][1] + \"/\", file_names, data2, [\"Runtime\"])\n",
    "    fetch_data(\"../optimal_threads/results/\" + machine + \"/optimal_threads_\" + configurations[exp_number - 1][2] + \"/\", file_names, data3, [\"Runtime\"])\n",
    "    \n",
    "    dataset1 = []\n",
    "    dataset2 = []\n",
    "    dataset3 = []\n",
    "\n",
    "    num_workers_min = 2\n",
    "    num_workers_step = 2\n",
    "    num_workers_values = range(num_workers_min, num_workers_max + num_workers_step, num_workers_step)\n",
    "    nwv_len = len(num_workers_values)\n",
    "    num_workers = num_workers_values[0]\n",
    "\n",
    "    num_cores_min = 2\n",
    "    num_cores_step = 2\n",
    "    num_cores_values = range(num_cores_min, num_cores_max + num_cores_step, num_cores_step)\n",
    "    ncv_len = len(num_cores_values)\n",
    "    num_cores = num_cores_values[0]\n",
    "\n",
    "    for i in range(len(data1)):\n",
    "        num_workers = num_workers_values[i % nwv_len]\n",
    "        num_cores = num_cores_values[(i // nwv_len) % ncv_len]\n",
    "\n",
    "        if (num_cores % 4 == 0) & (num_workers % 4 == 0) & (num_cores <= 12) & (num_workers <= 12):\n",
    "            dataset1.append([num_cores, num_workers, data1[i][1:].mean()[0]])\n",
    "\n",
    "    for i in range(len(data2)):\n",
    "        num_workers = num_workers_values[i % nwv_len]\n",
    "        num_cores = num_cores_values[(i // nwv_len) % ncv_len]\n",
    "\n",
    "        if (num_cores % 4 == 0) & (num_workers % 4 == 0) & (num_cores <= 12) & (num_workers <= 12):\n",
    "            dataset2.append([num_cores, num_workers, data2[i][1:].mean()[0]])\n",
    "\n",
    "    for i in range(len(data3)):\n",
    "        num_workers = num_workers_values[i % nwv_len]\n",
    "        num_cores = num_cores_values[(i // nwv_len) % ncv_len]\n",
    "\n",
    "        if (num_cores % 4 == 0) & (num_workers % 4 == 0) & (num_cores <= 12) & (num_workers <= 12):\n",
    "            dataset3.append([num_cores, num_workers, data3[i][1:].mean()[0]])\n",
    "\n",
    "    dataset1 = pd.DataFrame(dataset1)\n",
    "    dataset1.columns = [\"Num Cores\", \"Num Workers\", \"Time\"]\n",
    "\n",
    "    dataset2 = pd.DataFrame(dataset2)\n",
    "    dataset2.columns = [\"Num Cores\", \"Num Workers\", \"Time\"]\n",
    "\n",
    "    dataset3 = pd.DataFrame(dataset2)\n",
    "    dataset3.columns = [\"Num Cores\", \"Num Workers\", \"Time\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    independent_min_runtime1 = min(dataset1[\"Time\"])\n",
    "    independent_min_runtime2 = min(dataset2[\"Time\"])\n",
    "    independent_min_runtime3 = min(dataset2[\"Time\"])\n",
    "\n",
    "    inw1 = dataset1[dataset1[\"Time\"] == independent_min_runtime1][\"Num Workers\"].item()\n",
    "    inc1 = dataset1[dataset1[\"Time\"] == independent_min_runtime1][\"Num Cores\"].item()\n",
    "\n",
    "    inw2 = dataset2[dataset2[\"Time\"] == independent_min_runtime2][\"Num Workers\"].item()\n",
    "    inc2 = dataset2[dataset2[\"Time\"] == independent_min_runtime2][\"Num Cores\"].item()\n",
    "\n",
    "    inw3 = dataset3[dataset3[\"Time\"] == independent_min_runtime3][\"Num Workers\"].item()\n",
    "    inc3 = dataset3[dataset3[\"Time\"] == independent_min_runtime3][\"Num Cores\"].item()\n",
    "\n",
    "    imin_record = dataset.loc[(dataset[\"Num Cores 1\"] == inc1) & (dataset[\"Num Cores 2\"] == inc2) & (dataset[\"Num Cores 3\"] == inc3) & (dataset[\"Num Workers 1\"] == inw1) & (dataset[\"Num Workers 2\"] == inw2) & (dataset[\"Num Workers 3\"] == inw3)]\n",
    "    \n",
    "    imin_record_value = imin_record[\"Total Runtime\"].item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    idata = raw_dataset[(raw_dataset[\"Num Cores 1\"] == inc1) & (raw_dataset[\"Num Cores 2\"] == inc2) & (raw_dataset[\"Num Cores 3\"] == inc3) & (raw_dataset[\"Num Workers 1\"] == inw1) & (raw_dataset[\"Num Workers 2\"] == inw2) & (raw_dataset[\"Num Workers 3\"] == inw3)]\n",
    "    data  = raw_dataset[(raw_dataset[\"Num Cores 1\"] == nc1)  & (raw_dataset[\"Num Cores 2\"] == nc2)  & (raw_dataset[\"Num Cores 3\"] == nc3)  & (raw_dataset[\"Num Workers 1\"] == nw1)  & (raw_dataset[\"Num Workers 2\"] == nw2)  & (raw_dataset[\"Num Workers 3\"] == nw3)]\n",
    "    \n",
    "    table_data.append([configurations[exp_number - 1][0], configurations[exp_number - 1][1], configurations[exp_number - 1][2], str(mean_confidence_interval(idata[\"Total Runtime\"].values)), str(mean_confidence_interval(data[\"Total Runtime\"].values)), str(round(imin_record_value / min_record_value, 2))])\n",
    "    \n",
    "    print(' '.join(configurations[exp_number - 1]) + \" completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Program 1   | Program 2   | Program 3   | Independent Runtime   | Contention Aware Runtime   |   Speedup |\n",
      "|-------------+-------------+-------------+-----------------------+----------------------------+-----------|\n",
      "| cpu_small   | cpu_small   | cpu_small   | (292, 298, 305)       | (239, 251, 263)            |      1.18 |\n",
      "| cpu_small   | cpu_small   | cpu_large   | (267, 271, 276)       | (223, 236, 249)            |      1.14 |\n",
      "| cpu_small   | cpu_small   | vm_small    | (1117, 1144, 1172)    | (812, 826, 840)            |      1.39 |\n",
      "| cpu_small   | cpu_small   | vm_large    | (3333, 3390, 3447)    | (1548, 1602, 1655)         |      2.12 |\n",
      "| cpu_small   | cpu_large   | cpu_large   | (231, 236, 240)       | (206, 209, 212)            |      1.13 |\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(table_data, headers = [\"Program 1\", \"Program 2\", \"Program 3\", \"Independent Runtime\", \"Contention Aware Runtime\", \"Speedup\"], tablefmt = 'orgtbl'))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
