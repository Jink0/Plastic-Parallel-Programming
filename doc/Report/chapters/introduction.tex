%!TEX root = ../Report.tex

Throughout the history of computing, computer programmers and hardware engineers have exploited parallelism, with software and architectural innovation complementing technological improvements to provide increased performance. Architects have exploited bit and instruction parallelism, and now programmers are increasingly exploiting task/data parallelism in their applications \cite{concurrency_revolution} for various reasons \cite{free_lunch}.

It is recognised that writing correct and efficient parallel programs is hard \cite{parallel_challenges}, as the introduction of parallelism introduces a whole host of new problems \cite{sequential_to_parallel}, (e.g. unreproducible bugs due to race conditions, and difficulties debugging as high level instructions need to be decomposed into atomic assembly code to understand what is going on). The main purpose of multi-threading is improved performance, however parallel programs can often be slower then their serial counterparts, be it due to dependencies or hardware contention. Overhead must be balanced such that we don't introduce so much more work organizing threads and computations that our performance gains disappear.

Utilizing hardware efficiently is a major research challenge, especially considering that, today, a single program or library needs to deal with multiple different incarnations of the task it is trying to run. These arise from different circumstances, ranging from the hardware it is running on to the task size. Creating a ``one size fits all'' solution has become increasingly difficult, especially for high performance parallel applications. As such, there are solutions to help mitigate this problem \cite{petabricks}, which utilize the idea of plastic programming, that is, changing the specifics of an implementation depending on the circumstances. However, such solutions are only ``plastic'' at compile time, if circumstances change during runtime they cannot adapt. In particular, the most common situation a program may encounter would be the sharing of the computer's resources with other programs. This is again exacerbated for high performance parallel programs, as they typically attempt to use all the resources they can get their hands on.

Even when we have an ideal parallel program, often resources are shared between multiple programs and users, leading to resource contention. This is the case for most use cases, from the serious computing resources in data centres, to the low powered hardware of mobile phones. Even in our own computing labs, we have messages to the effect of "Do not leave applications running on this machine" or "please nice your programs", which are often unseen or disregarded.

It is known that in such a situation with two programs, with careful selection of program parameters, we can obtain a better average runtime for both programs \cite{lira}.

The aim of this project is to simplify the challenges of parallel programming and to provide improved performance by utilizing three key ideas:

\begin{itemize}
	\item Co-Scheduling
	\item Plastic Programming
	\item Skeleton Programming
\end{itemize}

and to investigate the performance ramifications. Combining these ideas results in these problems becoming particularly tricky, with many different challenges involved in combining them.

The layout of the report is as follows; In chapter \ref{chapter:background} we will provide an exploration of the ideas behind the project, and give a quick overview of how they are combined. In chapter \ref{chapter:design}, we will detail the thought process behind the design of our system, and then in chapter \ref{chapter:implementation} we will go into the specifics of the implementation of the system. Chapter \ref{chapter:experimental_methodology_and_program} presents a carefully selected series of experiments to assess this system, and in chapter \ref{chapter:results} we discuss the results of these experiments and their ramifications, and provide an overall conclusion to this year of the project. Chapter \ref{chapter:future_work_and_conclusions} provides the roadmap of future work for the second part of this two year MInf project and beyond, as well as a personal reflection upon the project as a whole.