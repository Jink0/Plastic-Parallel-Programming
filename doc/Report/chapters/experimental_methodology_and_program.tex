%!TEX root = ../Report.tex

***Discuss the systems used briefly, runtime of experiments? evaluation methodology (done with nothing else running?, Different array access patterns? How did you create a synthetic workload?)***

In this chapter, we describe our evaluation methodology, testing program, and the particular experiments we will run. The outcome of each of these experiments will be discussed in the results chapter, in the same order they are presented here.



\section{Evaluation Methodology}

The experiments were run on an Ubuntu virtual machine, with four cores, 4096MB of memory, and the rest of the system at idle.

To evaluate the performance of the system, we need to synthesize a *** CHECK HERE *** real-world workload. One which we can scale, so we can test different sized tasks and varying task distributions. To do this we use the Collatz function to generate a CPU intensive workload. A constant starting number is used, and the sequence is repeated multiple times, to scale the workload.

Multiple different statistics can be collected for each thread:

\begin{enumerate}
	\item Total runtime
	\item Time spent doing work
	\item Time spent in overhead
	\item Time blocked by main thread
	\item Number of tasks completed
\end{enumerate}

assortment of programs

test machine
repeats

future work - array access patterns



\section{Evaluation Program}



\section{Experiments}



The variables we can change are:

Input parameters:

\begin{itemize}
	\item Number of tasks
	\item Type of tasks (CPU Bottleneck/Memory Bottleneck)
	\item Task grain
	\item Task grain variance
\end{itemize}

Resources granted:

\begin{itemize}
	\item Number of CPU cores
\end{itemize}

Skeleton parameters:

\begin{itemize}
	\item Number of threads used
	\item Thread pinning
	\item Schedule
\end{itemize}




Tests:

Overhead of our system
Scalability
Absolute Performance
Benefits of Plasticity

Above with a single program and multiple programs

Overhead of metrics
Large array size small tasks peculiarity?